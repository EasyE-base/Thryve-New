#!/usr/bin/env python3
"""
Backend Testing Script for Thryve Fitness Platform
Testing AI-Powered Recommendation Engine System
"""

import requests
import json
import time
import os
from datetime import datetime

# Configuration
BASE_URL = "https://07dbb15a-6291-46a7-941f-21934bb5cdb1.preview.emergentagent.com"
SERVER_API_BASE = f"{BASE_URL}/server-api"

# Test data
TEST_USER_UID = "test-user-12345"
TEST_EMAIL = "testuser@thryve.com"
MOCK_FIREBASE_TOKEN = "mock-firebase-token-for-testing"

class AIRecommendationTester:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {MOCK_FIREBASE_TOKEN}'
        })
        self.test_results = []
        
    def log_test(self, test_name, success, message, response_data=None):
        """Log test results"""
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}: {message}")
        
        self.test_results.append({
            'test': test_name,
            'success': success,
            'message': message,
            'response_data': response_data,
            'timestamp': datetime.now().isoformat()
        })
    
    def test_class_recommendations(self):
        """Test GET /server-api/recommendations/classes - Personalized class recommendations"""
        print("\nüîÑ TESTING CLASS RECOMMENDATIONS SYSTEM")
        print("=" * 60)
        
        # Test 1: GET /server-api/recommendations/classes - Basic functionality
        try:
            response = self.session.get(f"{SERVER_API_BASE}/recommendations/classes")
            
            if response.status_code == 401:
                self.log_test("Class Recommendations - Authentication", True, "Correctly requires authentication (401)")
            elif response.status_code == 200:
                data = response.json()
                expected_fields = ['recommendations', 'totalCount', 'aiPowered', 'userId']
                if all(field in data for field in expected_fields):
                    self.log_test("Class Recommendations - Success", True, f"AI recommendations retrieved: {data['totalCount']} classes")
                    
                    # Validate AI-powered flag
                    if data.get('aiPowered') == True:
                        self.log_test("Class Recommendations - AI Powered", True, "AI-powered flag correctly set to true")
                    else:
                        self.log_test("Class Recommendations - AI Powered", False, f"AI-powered flag incorrect: {data.get('aiPowered')}")
                    
                    # Validate recommendation structure
                    if data['recommendations'] and len(data['recommendations']) > 0:
                        rec = data['recommendations'][0]
                        if 'recommendationReason' in rec and 'matchScore' in rec:
                            self.log_test("Class Recommendations - Structure", True, "Recommendation structure includes AI reasoning and match score")
                        else:
                            self.log_test("Class Recommendations - Structure", False, "Missing AI reasoning or match score in recommendations")
                    else:
                        self.log_test("Class Recommendations - Empty Results", True, "No recommendations returned (expected for new user)")
                        
                else:
                    missing_fields = [field for field in expected_fields if field not in data]
                    self.log_test("Class Recommendations - Response Structure", False, f"Missing fields: {missing_fields}")
            elif response.status_code == 500:
                self.log_test("Class Recommendations - OpenAI Integration", False, "Server error (500) - possible OpenAI API issue")
            else:
                self.log_test("Class Recommendations - Unexpected Status", False, f"Status: {response.status_code}, Response: {response.text}")
                
        except Exception as e:
            self.log_test("Class Recommendations - Exception", False, f"Exception occurred: {str(e)}")
        
        # Test 2: Validate OpenAI integration and fallback
        try:
            # Test with unauthenticated request to check error handling
            headers = {}  # No auth header
            response = requests.get(f"{SERVER_API_BASE}/recommendations/classes", headers=headers)
            
            if response.status_code == 401:
                self.log_test("Class Recommendations - Auth Protection", True, "Endpoint properly protected with authentication")
            else:
                self.log_test("Class Recommendations - Auth Protection", False, f"Authentication not properly enforced: {response.status_code}")
                
        except Exception as e:
            self.log_test("Class Recommendations - Auth Test", False, f"Exception: {str(e)}")
    
    def test_instructor_matching(self):
        """Test GET /server-api/recommendations/instructors - AI-powered instructor matching"""
        print("\nüë®‚Äçüè´ TESTING INSTRUCTOR MATCHING SYSTEM")
        print("=" * 60)
        
        # Test 1: GET /server-api/recommendations/instructors - Basic functionality
        try:
            response = self.session.get(f"{SERVER_API_BASE}/recommendations/instructors")
            
            if response.status_code == 401:
                self.log_test("Instructor Matching - Authentication", True, "Correctly requires authentication (401)")
            elif response.status_code == 200:
                data = response.json()
                expected_fields = ['instructors', 'totalCount', 'aiPowered', 'userId']
                if all(field in data for field in expected_fields):
                    self.log_test("Instructor Matching - Success", True, f"AI instructor matches retrieved: {data['totalCount']} instructors")
                    
                    # Validate AI-powered flag
                    if data.get('aiPowered') == True:
                        self.log_test("Instructor Matching - AI Powered", True, "AI-powered flag correctly set to true")
                    else:
                        self.log_test("Instructor Matching - AI Powered", False, f"AI-powered flag incorrect: {data.get('aiPowered')}")
                    
                    # Validate instructor match structure
                    if data['instructors'] and len(data['instructors']) > 0:
                        instructor = data['instructors'][0]
                        if 'matchReason' in instructor and 'compatibility' in instructor:
                            self.log_test("Instructor Matching - Structure", True, "Instructor match includes AI reasoning and compatibility score")
                        else:
                            self.log_test("Instructor Matching - Structure", False, "Missing AI reasoning or compatibility score in matches")
                    else:
                        self.log_test("Instructor Matching - Empty Results", True, "No instructor matches returned (expected for new user)")
                        
                else:
                    missing_fields = [field for field in expected_fields if field not in data]
                    self.log_test("Instructor Matching - Response Structure", False, f"Missing fields: {missing_fields}")
            elif response.status_code == 500:
                self.log_test("Instructor Matching - OpenAI Integration", False, "Server error (500) - possible OpenAI API issue")
            else:
                self.log_test("Instructor Matching - Unexpected Status", False, f"Status: {response.status_code}, Response: {response.text}")
                
        except Exception as e:
            self.log_test("Instructor Matching - Exception", False, f"Exception occurred: {str(e)}")
        
        # Test 2: Validate personality-based matching
        try:
            # Test with unauthenticated request
            headers = {}
            response = requests.get(f"{SERVER_API_BASE}/recommendations/instructors", headers=headers)
            
            if response.status_code == 401:
                self.log_test("Instructor Matching - Auth Protection", True, "Endpoint properly protected with authentication")
            else:
                self.log_test("Instructor Matching - Auth Protection", False, f"Authentication not properly enforced: {response.status_code}")
                
        except Exception as e:
            self.log_test("Instructor Matching - Auth Test", False, f"Exception: {str(e)}")
    
    def test_natural_language_search(self):
        """Test GET /server-api/ai/search - Natural language search processing"""
        print("\nüîç TESTING NATURAL LANGUAGE SEARCH SYSTEM")
        print("=" * 60)
        
        # Test 1: Basic natural language search
        try:
            search_query = "I want a relaxing yoga class in the morning for beginners"
            response = self.session.get(f"{SERVER_API_BASE}/ai/search?q={search_query}")
            
            if response.status_code == 200:
                data = response.json()
                expected_fields = ['results', 'aiAnalysis', 'totalFound', 'query', 'aiPowered']
                if all(field in data for field in expected_fields):
                    self.log_test("Natural Language Search - Success", True, f"AI search processed: {data['totalFound']} results found")
                    
                    # Validate AI analysis
                    if data.get('aiAnalysis') and isinstance(data['aiAnalysis'], dict):
                        analysis = data['aiAnalysis']
                        if 'workoutTypes' in analysis or 'difficultyLevel' in analysis:
                            self.log_test("Natural Language Search - AI Analysis", True, "AI successfully analyzed natural language query")
                        else:
                            self.log_test("Natural Language Search - AI Analysis", False, "AI analysis missing expected fields")
                    else:
                        self.log_test("Natural Language Search - AI Analysis", False, "Missing or invalid AI analysis")
                    
                    # Validate query processing
                    if data.get('query') == search_query:
                        self.log_test("Natural Language Search - Query Processing", True, "Original query preserved correctly")
                    else:
                        self.log_test("Natural Language Search - Query Processing", False, "Query not preserved correctly")
                        
                else:
                    missing_fields = [field for field in expected_fields if field not in data]
                    self.log_test("Natural Language Search - Response Structure", False, f"Missing fields: {missing_fields}")
            elif response.status_code == 500:
                self.log_test("Natural Language Search - OpenAI Integration", False, "Server error (500) - possible OpenAI API issue")
            else:
                self.log_test("Natural Language Search - Unexpected Status", False, f"Status: {response.status_code}, Response: {response.text}")
                
        except Exception as e:
            self.log_test("Natural Language Search - Exception", False, f"Exception occurred: {str(e)}")
        
        # Test 2: Search without query parameter
        try:
            response = self.session.get(f"{SERVER_API_BASE}/ai/search")
            
            if response.status_code == 400:
                self.log_test("Natural Language Search - Validation", True, "Correctly validates missing query parameter (400)")
            else:
                self.log_test("Natural Language Search - Validation", False, f"Should return 400 for missing query: {response.status_code}")
                
        except Exception as e:
            self.log_test("Natural Language Search - Validation Test", False, f"Exception: {str(e)}")
        
        # Test 3: Complex search query
        try:
            complex_query = "high intensity cardio workout for weight loss in the evening"
            response = self.session.get(f"{SERVER_API_BASE}/ai/search?q={complex_query}")
            
            if response.status_code == 200:
                data = response.json()
                if data.get('aiAnalysis'):
                    analysis = data['aiAnalysis']
                    # Check if AI correctly identified intensity and goals
                    if 'intensity' in analysis or 'goals' in analysis:
                        self.log_test("Natural Language Search - Complex Query", True, "AI successfully processed complex query with multiple parameters")
                    else:
                        self.log_test("Natural Language Search - Complex Query", False, "AI failed to extract complex query parameters")
                else:
                    self.log_test("Natural Language Search - Complex Query", False, "No AI analysis for complex query")
            else:
                self.log_test("Natural Language Search - Complex Query", False, f"Failed to process complex query: {response.status_code}")
                
        except Exception as e:
            self.log_test("Natural Language Search - Complex Query", False, f"Exception: {str(e)}")
    
    def test_workout_plan_generation(self):
        """Test POST /server-api/ai/workout-plan - Personalized workout plan creation"""
        print("\nüí™ TESTING WORKOUT PLAN GENERATION SYSTEM")
        print("=" * 60)
        
        # Test 1: Basic workout plan generation
        try:
            workout_data = {
                "goals": ["weight loss", "strength building"],
                "duration": 4,  # 4 weeks
                "preferences": ["home workouts", "no equipment needed"]
            }
            
            response = self.session.post(f"{SERVER_API_BASE}/ai/workout-plan", json=workout_data)
            
            if response.status_code == 401:
                self.log_test("Workout Plan Generation - Authentication", True, "Correctly requires authentication (401)")
            elif response.status_code == 200:
                data = response.json()
                expected_fields = ['workoutPlan', 'aiGenerated', 'timestamp']
                if all(field in data for field in expected_fields):
                    self.log_test("Workout Plan Generation - Success", True, "AI workout plan generated successfully")
                    
                    # Validate AI-generated flag
                    if data.get('aiGenerated') == True:
                        self.log_test("Workout Plan Generation - AI Generated", True, "AI-generated flag correctly set")
                    else:
                        self.log_test("Workout Plan Generation - AI Generated", False, "AI-generated flag incorrect")
                    
                    # Validate workout plan structure
                    plan = data.get('workoutPlan', {})
                    plan_fields = ['planSummary', 'weeklyBreakdown', 'nutritionTips', 'recoveryTips']
                    if any(field in plan for field in plan_fields):
                        self.log_test("Workout Plan Generation - Structure", True, "Workout plan contains expected structure")
                    else:
                        self.log_test("Workout Plan Generation - Structure", False, "Workout plan missing expected fields")
                        
                else:
                    missing_fields = [field for field in expected_fields if field not in data]
                    self.log_test("Workout Plan Generation - Response Structure", False, f"Missing fields: {missing_fields}")
            elif response.status_code == 500:
                self.log_test("Workout Plan Generation - OpenAI Integration", False, "Server error (500) - possible OpenAI API issue")
            else:
                self.log_test("Workout Plan Generation - Unexpected Status", False, f"Status: {response.status_code}, Response: {response.text}")
                
        except Exception as e:
            self.log_test("Workout Plan Generation - Exception", False, f"Exception occurred: {str(e)}")
        
        # Test 2: Validation of required fields
        try:
            invalid_data = {"preferences": ["home workouts"]}  # Missing goals and duration
            response = self.session.post(f"{SERVER_API_BASE}/ai/workout-plan", json=invalid_data)
            
            if response.status_code == 400:
                self.log_test("Workout Plan Generation - Validation", True, "Correctly validates required fields (400)")
            elif response.status_code == 401:
                self.log_test("Workout Plan Generation - Auth First", True, "Authentication checked before validation")
            else:
                self.log_test("Workout Plan Generation - Validation", False, f"Should validate required fields: {response.status_code}")
                
        except Exception as e:
            self.log_test("Workout Plan Generation - Validation Test", False, f"Exception: {str(e)}")
        
        # Test 3: Unauthenticated request
        try:
            headers = {}  # No auth
            workout_data = {
                "goals": ["flexibility"],
                "duration": 2,
                "preferences": ["yoga"]
            }
            response = requests.post(f"{SERVER_API_BASE}/ai/workout-plan", json=workout_data, headers=headers)
            
            if response.status_code == 401:
                self.log_test("Workout Plan Generation - Auth Protection", True, "Endpoint properly protected with authentication")
            else:
                self.log_test("Workout Plan Generation - Auth Protection", False, f"Authentication not enforced: {response.status_code}")
                
        except Exception as e:
            self.log_test("Workout Plan Generation - Auth Test", False, f"Exception: {str(e)}")
    
    def test_predictive_analytics(self):
        """Test GET /server-api/ai/analytics - AI-powered business insights"""
        print("\nüìä TESTING PREDICTIVE ANALYTICS SYSTEM")
        print("=" * 60)
        
        # Test 1: Basic predictive analytics
        try:
            response = self.session.get(f"{SERVER_API_BASE}/ai/analytics")
            
            if response.status_code == 401:
                self.log_test("Predictive Analytics - Authentication", True, "Correctly requires authentication (401)")
            elif response.status_code == 403:
                self.log_test("Predictive Analytics - Authorization", True, "Correctly requires merchant/admin role (403)")
            elif response.status_code == 200:
                data = response.json()
                expected_fields = ['analytics', 'aiPowered', 'timestamp', 'accessLevel']
                if all(field in data for field in expected_fields):
                    self.log_test("Predictive Analytics - Success", True, "AI analytics generated successfully")
                    
                    # Validate AI-powered flag
                    if data.get('aiPowered') == True:
                        self.log_test("Predictive Analytics - AI Powered", True, "AI-powered flag correctly set")
                    else:
                        self.log_test("Predictive Analytics - AI Powered", False, "AI-powered flag incorrect")
                    
                    # Validate analytics structure
                    analytics = data.get('analytics', {})
                    analytics_fields = ['emergingTrends', 'recommendedNewClasses', 'userRetentionStrategies', 'businessOpportunities']
                    if any(field in analytics for field in analytics_fields):
                        self.log_test("Predictive Analytics - Structure", True, "Analytics contains expected business insights")
                    else:
                        self.log_test("Predictive Analytics - Structure", False, "Analytics missing expected insight fields")
                        
                else:
                    missing_fields = [field for field in expected_fields if field not in data]
                    self.log_test("Predictive Analytics - Response Structure", False, f"Missing fields: {missing_fields}")
            elif response.status_code == 500:
                self.log_test("Predictive Analytics - OpenAI Integration", False, "Server error (500) - possible OpenAI API issue")
            else:
                self.log_test("Predictive Analytics - Unexpected Status", False, f"Status: {response.status_code}, Response: {response.text}")
                
        except Exception as e:
            self.log_test("Predictive Analytics - Exception", False, f"Exception occurred: {str(e)}")
        
        # Test 2: Unauthenticated request
        try:
            headers = {}  # No auth
            response = requests.get(f"{SERVER_API_BASE}/ai/analytics", headers=headers)
            
            if response.status_code == 401:
                self.log_test("Predictive Analytics - Auth Protection", True, "Endpoint properly protected with authentication")
            else:
                self.log_test("Predictive Analytics - Auth Protection", False, f"Authentication not enforced: {response.status_code}")
                
        except Exception as e:
            self.log_test("Predictive Analytics - Auth Test", False, f"Exception: {str(e)}")
    
    def test_openai_integration(self):
        """Test OpenAI API integration and error handling"""
        print("\nü§ñ TESTING OPENAI INTEGRATION & ERROR HANDLING")
        print("=" * 60)
        
        # Test 1: Check if OpenAI API key is configured
        try:
            # This test will indirectly check OpenAI integration by making a request
            # that should use OpenAI (class recommendations)
            response = self.session.get(f"{SERVER_API_BASE}/recommendations/classes")
            
            if response.status_code == 401:
                self.log_test("OpenAI Integration - API Key Config", True, "Authentication required (cannot test OpenAI without auth)")
            elif response.status_code == 500:
                # Check if error message indicates OpenAI issues
                try:
                    error_data = response.json()
                    if 'openai' in str(error_data).lower() or 'api key' in str(error_data).lower():
                        self.log_test("OpenAI Integration - API Key Config", False, "OpenAI API key configuration issue detected")
                    else:
                        self.log_test("OpenAI Integration - API Key Config", False, "Server error but not clearly OpenAI related")
                except:
                    self.log_test("OpenAI Integration - API Key Config", False, "Server error (500) - possible OpenAI issue")
            elif response.status_code == 200:
                self.log_test("OpenAI Integration - API Key Config", True, "OpenAI integration appears to be working")
            else:
                self.log_test("OpenAI Integration - API Key Config", False, f"Unexpected response: {response.status_code}")
                
        except Exception as e:
            self.log_test("OpenAI Integration - API Key Config", False, f"Exception: {str(e)}")
        
        # Test 2: Test rate limiting and error handling
        try:
            # Make multiple rapid requests to test rate limiting
            responses = []
            for i in range(3):
                response = self.session.get(f"{SERVER_API_BASE}/ai/search?q=test query {i}")
                responses.append(response.status_code)
                time.sleep(0.1)  # Small delay
            
            # Check if any rate limiting occurred
            if any(status == 429 for status in responses):
                self.log_test("OpenAI Integration - Rate Limiting", True, "Rate limiting properly implemented")
            elif all(status in [200, 401] for status in responses):
                self.log_test("OpenAI Integration - Rate Limiting", True, "No rate limiting issues detected in rapid requests")
            else:
                self.log_test("OpenAI Integration - Rate Limiting", False, f"Unexpected status codes: {responses}")
                
        except Exception as e:
            self.log_test("OpenAI Integration - Rate Limiting", False, f"Exception: {str(e)}")
        
        # Test 3: Test fallback mechanisms
        try:
            # Test if system gracefully handles OpenAI failures
            # This is tested indirectly through the recommendation endpoints
            response = self.session.get(f"{SERVER_API_BASE}/recommendations/classes")
            
            if response.status_code in [200, 401]:
                self.log_test("OpenAI Integration - Fallback Mechanisms", True, "System handles OpenAI responses appropriately")
            elif response.status_code == 500:
                # Check if there's a graceful fallback
                try:
                    error_data = response.json()
                    if 'error' in error_data:
                        self.log_test("OpenAI Integration - Fallback Mechanisms", True, "System provides error response for OpenAI failures")
                    else:
                        self.log_test("OpenAI Integration - Fallback Mechanisms", False, "No proper error handling for OpenAI failures")
                except:
                    self.log_test("OpenAI Integration - Fallback Mechanisms", False, "Poor error handling for OpenAI failures")
            else:
                self.log_test("OpenAI Integration - Fallback Mechanisms", False, f"Unexpected response: {response.status_code}")
                
        except Exception as e:
            self.log_test("OpenAI Integration - Fallback Mechanisms", False, f"Exception: {str(e)}")
    
    def test_database_integration(self):
        """Test AI service integration with MongoDB collections"""
        print("\nüóÑÔ∏è TESTING DATABASE INTEGRATION")
        print("=" * 60)
        
        # Test 1: User profile integration for recommendations
        try:
            response = self.session.get(f"{SERVER_API_BASE}/recommendations/classes")
            
            if response.status_code == 401:
                self.log_test("Database Integration - User Profiles", True, "Authentication required (cannot test without auth)")
            elif response.status_code == 200:
                data = response.json()
                if 'userId' in data:
                    self.log_test("Database Integration - User Profiles", True, "User profile integration working")
                else:
                    self.log_test("Database Integration - User Profiles", False, "User profile not properly integrated")
            else:
                self.log_test("Database Integration - User Profiles", False, f"Unexpected response: {response.status_code}")
                
        except Exception as e:
            self.log_test("Database Integration - User Profiles", False, f"Exception: {str(e)}")
        
        # Test 2: Search query logging
        try:
            search_query = "test database integration query"
            response = self.session.get(f"{SERVER_API_BASE}/ai/search?q={search_query}")
            
            if response.status_code == 200:
                data = response.json()
                if 'query' in data and data['query'] == search_query:
                    self.log_test("Database Integration - Search Logging", True, "Search query properly processed and logged")
                else:
                    self.log_test("Database Integration - Search Logging", False, "Search query not properly handled")
            elif response.status_code == 401:
                self.log_test("Database Integration - Search Logging", True, "Search endpoint accessible (auth not required for search)")
            else:
                self.log_test("Database Integration - Search Logging", False, f"Search endpoint issue: {response.status_code}")
                
        except Exception as e:
            self.log_test("Database Integration - Search Logging", False, f"Exception: {str(e)}")
        
        # Test 3: Class and instructor data retrieval
        try:
            response = self.session.get(f"{SERVER_API_BASE}/recommendations/instructors")
            
            if response.status_code == 401:
                self.log_test("Database Integration - Instructor Data", True, "Authentication required (cannot test without auth)")
            elif response.status_code == 200:
                data = response.json()
                if 'instructors' in data:
                    self.log_test("Database Integration - Instructor Data", True, "Instructor data retrieval integrated")
                else:
                    self.log_test("Database Integration - Instructor Data", False, "Instructor data not properly retrieved")
            else:
                self.log_test("Database Integration - Instructor Data", False, f"Unexpected response: {response.status_code}")
                
        except Exception as e:
            self.log_test("Database Integration - Instructor Data", False, f"Exception: {str(e)}")
    
    def test_performance_and_optimization(self):
        """Test response times and performance optimization"""
        print("\n‚ö° TESTING PERFORMANCE & OPTIMIZATION")
        print("=" * 60)
        
        # Test 1: Response time for AI endpoints
        try:
            start_time = time.time()
            response = self.session.get(f"{SERVER_API_BASE}/ai/search?q=quick performance test")
            end_time = time.time()
            
            response_time = end_time - start_time
            
            if response.status_code in [200, 401]:
                if response_time < 10.0:  # 10 seconds threshold
                    self.log_test("Performance - Response Time", True, f"AI search response time: {response_time:.2f}s (acceptable)")
                else:
                    self.log_test("Performance - Response Time", False, f"AI search response time: {response_time:.2f}s (too slow)")
            else:
                self.log_test("Performance - Response Time", False, f"Cannot test performance due to status: {response.status_code}")
                
        except Exception as e:
            self.log_test("Performance - Response Time", False, f"Exception: {str(e)}")
        
        # Test 2: Concurrent request handling
        try:
            import threading
            import queue
            
            results_queue = queue.Queue()
            
            def make_request():
                try:
                    response = self.session.get(f"{SERVER_API_BASE}/ai/search?q=concurrent test")
                    results_queue.put(response.status_code)
                except Exception as e:
                    results_queue.put(f"error: {str(e)}")
            
            # Create 3 concurrent threads
            threads = []
            for i in range(3):
                thread = threading.Thread(target=make_request)
                threads.append(thread)
                thread.start()
            
            # Wait for all threads to complete
            for thread in threads:
                thread.join()
            
            # Collect results
            results = []
            while not results_queue.empty():
                results.append(results_queue.get())
            
            if len(results) == 3:
                if all(isinstance(r, int) for r in results):
                    self.log_test("Performance - Concurrent Requests", True, f"Handled 3 concurrent requests: {results}")
                else:
                    self.log_test("Performance - Concurrent Requests", False, f"Some requests failed: {results}")
            else:
                self.log_test("Performance - Concurrent Requests", False, f"Expected 3 results, got {len(results)}")
                
        except Exception as e:
            self.log_test("Performance - Concurrent Requests", False, f"Exception: {str(e)}")
        
        # Test 3: Memory usage optimization (indirect test)
        try:
            # Make multiple requests to test for memory leaks
            status_codes = []
            for i in range(5):
                response = self.session.get(f"{SERVER_API_BASE}/ai/search?q=memory test {i}")
                status_codes.append(response.status_code)
                time.sleep(0.2)
            
            # If all requests return consistent status codes, memory handling is likely good
            if len(set(status_codes)) <= 2:  # Allow for auth vs non-auth differences
                self.log_test("Performance - Memory Optimization", True, f"Consistent responses across multiple requests: {set(status_codes)}")
            else:
                self.log_test("Performance - Memory Optimization", False, f"Inconsistent responses may indicate memory issues: {status_codes}")
                
        except Exception as e:
            self.log_test("Performance - Memory Optimization", False, f"Exception: {str(e)}")
    
    def run_all_tests(self):
        """Run all AI recommendation engine test suites"""
        print("üöÄ STARTING AI-POWERED RECOMMENDATION ENGINE BACKEND TESTING")
        print("=" * 80)
        
        start_time = time.time()
        
        # Run all test suites
        self.test_class_recommendations()
        self.test_instructor_matching()
        self.test_natural_language_search()
        self.test_workout_plan_generation()
        self.test_predictive_analytics()
        self.test_openai_integration()
        self.test_database_integration()
        self.test_performance_and_optimization()
        
        # Generate summary
        end_time = time.time()
        duration = end_time - start_time
        
        total_tests = len(self.test_results)
        passed_tests = len([t for t in self.test_results if t['success']])
        failed_tests = total_tests - passed_tests
        
        print("\n" + "=" * 80)
        print("üìã AI RECOMMENDATION ENGINE TEST SUMMARY")
        print("=" * 80)
        print(f"Total Tests: {total_tests}")
        print(f"‚úÖ Passed: {passed_tests}")
        print(f"‚ùå Failed: {failed_tests}")
        print(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")
        print(f"Duration: {duration:.2f} seconds")
        
        # Show failed tests
        if failed_tests > 0:
            print(f"\n‚ùå FAILED TESTS ({failed_tests}):")
            for test in self.test_results:
                if not test['success']:
                    print(f"  ‚Ä¢ {test['test']}: {test['message']}")
        
        # Show critical findings
        print(f"\nüîç CRITICAL FINDINGS:")
        
        # Check for OpenAI integration issues
        openai_issues = []
        for test in self.test_results:
            if "OpenAI" in test['message'] and not test['success']:
                openai_issues.append(test['test'])
        
        if openai_issues:
            print(f"  ‚Ä¢ ‚ö†Ô∏è OpenAI Integration Issues: {', '.join(openai_issues)}")
        else:
            print(f"  ‚Ä¢ ‚úÖ OpenAI integration appears to be working")
        
        # Check authentication
        auth_working = any("Correctly requires authentication" in test['message'] for test in self.test_results)
        if auth_working:
            print(f"  ‚Ä¢ ‚úÖ Authentication protection is working correctly")
        else:
            print(f"  ‚Ä¢ ‚ùå Authentication protection issues detected")
        
        # Check AI-powered features
        ai_features = any("AI-powered flag correctly set" in test['message'] for test in self.test_results)
        if ai_features:
            print(f"  ‚Ä¢ ‚úÖ AI-powered features are properly flagged")
        else:
            print(f"  ‚Ä¢ ‚ö†Ô∏è AI-powered feature flagging may have issues")
        
        return {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': failed_tests,
            'success_rate': (passed_tests/total_tests)*100,
            'duration': duration,
            'test_results': self.test_results
        }

if __name__ == "__main__":
    tester = AIRecommendationTester()
    results = tester.run_all_tests()
    
    # Save results to file
    with open('/app/ai_backend_test_results.json', 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nüíæ Test results saved to: /app/ai_backend_test_results.json")